{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRI0k_iw4T5v"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "        # open the file\n",
        "        file = open(filename, mode='rt', encoding='utf-8')\n",
        "\n",
        "        # read all text\n",
        "        text = file.read()\n",
        "        file.close()\n",
        "        return text"
      ],
      "metadata": {
        "id": "UZ1fGquX4fr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split a text into sentences\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents"
      ],
      "metadata": {
        "id": "vq-Wmemd4jxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_text(\"/content/deu.txt\")\n",
        "eng_pes = to_lines(data)\n",
        "eng_pes = array(eng_pes)"
      ],
      "metadata": {
        "id": "oEIA6v4jgULT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_pes"
      ],
      "metadata": {
        "id": "Qhiho0PVhAmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([['Go.', 'Geh.',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
        "       ['Hi.', 'Hallo!',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
        "       ['Hi.', 'Grüß Gott!',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
        "       ...,\n",
        "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
        "        'Wenn jemand Fremdes dir sagt, dass du dich wie ein Muttersprachler anhörst, bedeutet das wahrscheinlich: Er hat etwas an deinem Sprechen bemerkt, dass dich als Nicht-Muttersprachler verraten hat. Mit anderen Worten: Du hörst dich nicht wirklich wie ein Muttersprachler an.',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #3807493 (Tickler)'],\n",
        "       [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n",
        "        'Wenn jemand, der nicht weiß, woher man kommt, sagt, man erwecke doch den Eindruck, Muttersprachler zu sein, so hat man Grund zu der Annahme, dass ihm an der Sprache irgendetwas aufgefallen ist, woran er erkannt hat, dass man eben keiner ist\\xa0– dass man diesen Eindruck mit anderen Worten eigentlich nicht erweckt.',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #8836704 (Pfirsichbaeumchen)'],\n",
        "       ['Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.',\n",
        "        'Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt\\xa0leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7729416 (Pfirsichbaeumchen)']],\n",
        "      dtype='<U537')"
      ],
      "metadata": {
        "id": "t4GeqLPJcuAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_pes = eng_pes[:50000,:]"
      ],
      "metadata": {
        "id": "gR91hWyM4kQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "eng_pes[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in eng_pes[:,0]]\n",
        "eng_pes[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in eng_pes[:,1]]\n",
        "\n",
        "eng_pes\n"
      ],
      "metadata": {
        "id": "aRW35fNr8aiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([['Go', 'Geh',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
        "       ['Hi', 'Hallo',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
        "       ['Hi', 'Grüß Gott',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
        "       ...,\n",
        "       ['Im giving up smoking', 'Ich höre mit dem Rauchen auf',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #256952 (minshirui) & #407184 (MUIRIEL)'],\n",
        "       ['Im glad I was nearby', 'Ich bin froh dass ich in der Nähe war',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2547219 (CK) & #3448316 (Pfirsichbaeumchen)'],\n",
        "       ['Im glad Tom has gone', 'Ich bin froh dass Tom weg ist',\n",
        "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2547217 (CK) & #5299642 (Pfirsichbaeumchen)']],\n",
        "      dtype='<U537')"
      ],
      "metadata": {
        "id": "VjPlNapYc4t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert text to lowercase\n",
        "for i in range(len(eng_pes)):\n",
        "    eng_pes[i,0] = eng_pes[i,0].lower()\n",
        "    eng_pes[i,1] = eng_pes[i,1].lower()"
      ],
      "metadata": {
        "id": "viIWH_YZ9VIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty lists\n",
        "eng_l = []\n",
        "pes_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in eng_pes[:,0]:\n",
        "      eng_l.append(len(i.split()))\n",
        "\n",
        "for i in eng_pes[:,1]:\n",
        "      pes_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'pes':pes_l})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gph3bbL29h2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "U-9cGF7O-Lun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(eng_pes[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)"
      ],
      "metadata": {
        "id": "Unrw0P43-pB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "English Vocabulary Size: 6256"
      ],
      "metadata": {
        "id": "QUTv5ICXc-p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare Persian tokenizer\n",
        "pes_tokenizer = tokenization(eng_pes[:, 1])\n",
        "pes_vocab_size = len(pes_tokenizer.word_index) + 1\n",
        "\n",
        "pes_length = 8\n",
        "print('German Vocabulary Size: %d' % pes_vocab_size)"
      ],
      "metadata": {
        "id": "wWAmniTU-uU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "German Vocabulary Size: 10329"
      ],
      "metadata": {
        "id": "G6A1hYw-dAZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "metadata": {
        "id": "fYveyNps-9dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "gq-wxNgBDCya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(eng_pes, test_size=0.2, random_state = 12)"
      ],
      "metadata": {
        "id": "y1kcKJ6kDCOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(pes_tokenizer, pes_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(pes_tokenizer, pes_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n"
      ],
      "metadata": {
        "id": "8z3-jHUsDISv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import MultiHeadAttention"
      ],
      "metadata": {
        "id": "vwV3u9IM4qfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proposed Model to just add Bidirectional LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from keras import optimizers\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(Bidirectional(LSTM(units, return_sequences=True)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(units)))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))  # Regular LSTM in decoder\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "\n",
        "    rms = optimizers.RMSprop(lr=0.001)\n",
        "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1uL1S2NwsvUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multi-head_self attention with bi-directional lstm\n",
        "from tensorflow.keras.layers import MultiHeadAttention, RepeatVector, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    input_layer = Input(shape=(in_timesteps,))\n",
        "    embedding_layer = Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True)(input_layer)\n",
        "    lstm_layer = Bidirectional(LSTM(units, return_sequences=True))(embedding_layer)\n",
        "    attention = MultiHeadAttention(num_heads=2, key_dim=units)(lstm_layer, lstm_layer)\n",
        "    dropout = Dropout(0.5)(attention)\n",
        "    lstm_layer_2 = Bidirectional(LSTM(units))(dropout)\n",
        "    repeat_vector = RepeatVector(out_timesteps)(lstm_layer_2)\n",
        "    lstm_layer_3 = LSTM(units, return_sequences=True)(repeat_vector)\n",
        "    output_layer = Dense(out_vocab, activation='softmax')(lstm_layer_3)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    rms = optimizers.RMSprop(lr=0.001)\n",
        "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "icBEL5wv0073"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kaggle Proposed Model\n",
        "# build NMT model\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    rms = optimizers.RMSprop(lr=0.001)\n",
        "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JnUZLviygJos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model compilation\n",
        "model = define_model(pes_vocab_size, eng_vocab_size, pes_length, eng_length, 512)"
      ],
      "metadata": {
        "id": "6n_w5NziDIvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Proposed_model_5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint],\n",
        "                    verbose=1)\n"
      ],
      "metadata": {
        "id": "ft0KyZMSEfIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 3.8573\n",
        "Epoch 1: val_loss improved from inf to 3.09141, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 82s 902ms/step - loss: 3.8573 - val_loss: 3.0914\n",
        "Epoch 2/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.9161\n",
        "Epoch 2: val_loss improved from 3.09141 to 2.88892, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 51s 818ms/step - loss: 2.9161 - val_loss: 2.8889\n",
        "Epoch 3/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.8231\n",
        "Epoch 3: val_loss improved from 2.88892 to 2.85578, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 804ms/step - loss: 2.8231 - val_loss: 2.8558\n",
        "Epoch 4/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7807\n",
        "Epoch 4: val_loss improved from 2.85578 to 2.79740, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 809ms/step - loss: 2.7807 - val_loss: 2.7974\n",
        "Epoch 5/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7493\n",
        "Epoch 5: val_loss improved from 2.79740 to 2.75987, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 808ms/step - loss: 2.7493 - val_loss: 2.7599\n",
        "Epoch 6/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7224\n",
        "Epoch 6: val_loss improved from 2.75987 to 2.73565, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 49s 790ms/step - loss: 2.7224 - val_loss: 2.7357\n",
        "Epoch 7/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6880\n",
        "Epoch 7: val_loss improved from 2.73565 to 2.68262, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 52s 842ms/step - loss: 2.6880 - val_loss: 2.6826\n",
        "Epoch 8/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6538\n",
        "Epoch 8: val_loss improved from 2.68262 to 2.66822, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 52s 838ms/step - loss: 2.6538 - val_loss: 2.6682\n",
        "Epoch 9/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6278\n",
        "Epoch 9: val_loss improved from 2.66822 to 2.64200, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 55s 877ms/step - loss: 2.6278 - val_loss: 2.6420\n",
        "Epoch 10/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6051\n",
        "Epoch 10: val_loss did not improve from 2.64200\n",
        "63/63 [==============================] - 9s 149ms/step - loss: 2.6051 - val_loss: 2.6480\n",
        "Epoch 11/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5882\n",
        "Epoch 11: val_loss improved from 2.64200 to 2.62742, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 54s 871ms/step - loss: 2.5882 - val_loss: 2.6274\n",
        "Epoch 12/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5727\n",
        "Epoch 12: val_loss improved from 2.62742 to 2.61444, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 54s 869ms/step - loss: 2.5727 - val_loss: 2.6144\n",
        "Epoch 13/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5488\n",
        "Epoch 13: val_loss improved from 2.61444 to 2.59372, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 802ms/step - loss: 2.5488 - val_loss: 2.5937\n",
        "Epoch 14/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5212\n",
        "Epoch 14: val_loss improved from 2.59372 to 2.56922, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 55s 881ms/step - loss: 2.5212 - val_loss: 2.5692\n",
        "Epoch 15/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.4936\n",
        "Epoch 15: val_loss improved from 2.56922 to 2.51500, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 799ms/step - loss: 2.4936 - val_loss: 2.5150\n",
        "Epoch 16/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.4597\n",
        "Epoch 16: val_loss improved from 2.51500 to 2.50523, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 800ms/step - loss: 2.4597 - val_loss: 2.5052\n",
        "Epoch 17/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.4649\n",
        "Epoch 17: val_loss improved from 2.50523 to 2.46268, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 51s 822ms/step - loss: 2.4649 - val_loss: 2.4627\n",
        "Epoch 18/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3942\n",
        "Epoch 18: val_loss improved from 2.46268 to 2.46084, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 52s 838ms/step - loss: 2.3942 - val_loss: 2.4608\n",
        "Epoch 19/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3614\n",
        "Epoch 19: val_loss improved from 2.46084 to 2.41669, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 49s 793ms/step - loss: 2.3614 - val_loss: 2.4167\n",
        "Epoch 20/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3396\n",
        "Epoch 20: val_loss improved from 2.41669 to 2.38914, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 50s 805ms/step - loss: 2.3396 - val_loss: 2.3891\n",
        "Epoch 21/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3130\n",
        "Epoch 21: val_loss did not improve from 2.38914\n",
        "63/63 [==============================] - 10s 151ms/step - loss: 2.3130 - val_loss: 2.4117\n",
        "Epoch 22/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2931\n",
        "Epoch 22: val_loss improved from 2.38914 to 2.38278, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 49s 792ms/step - loss: 2.2931 - val_loss: 2.3828\n",
        "Epoch 23/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2725\n",
        "Epoch 23: val_loss improved from 2.38278 to 2.34803, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 52s 829ms/step - loss: 2.2725 - val_loss: 2.3480\n",
        "Epoch 24/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2547\n",
        "Epoch 24: val_loss improved from 2.34803 to 2.33404, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 54s 869ms/step - loss: 2.2547 - val_loss: 2.3340\n",
        "Epoch 25/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2362\n",
        "Epoch 25: val_loss improved from 2.33404 to 2.32444, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 54s 873ms/step - loss: 2.2362 - val_loss: 2.3244\n",
        "Epoch 26/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2230\n",
        "Epoch 26: val_loss improved from 2.32444 to 2.32287, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 55s 883ms/step - loss: 2.2230 - val_loss: 2.3229\n",
        "Epoch 27/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2049\n",
        "Epoch 27: val_loss improved from 2.32287 to 2.28887, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 54s 873ms/step - loss: 2.2049 - val_loss: 2.2889\n",
        "Epoch 28/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.1899\n",
        "Epoch 28: val_loss did not improve from 2.28887\n",
        "63/63 [==============================] - 10s 150ms/step - loss: 2.1899 - val_loss: 2.2898\n",
        "Epoch 29/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.1798\n",
        "Epoch 29: val_loss improved from 2.28887 to 2.26723, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 51s 817ms/step - loss: 2.1798 - val_loss: 2.2672\n",
        "Epoch 30/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.1630\n",
        "Epoch 30: val_loss improved from 2.26723 to 2.25981, saving model to Proposed_model_5\n",
        "63/63 [==============================] - 53s 846ms/step - loss: 2.1630 - val_loss: 2.2598"
      ],
      "metadata": {
        "id": "9QgW9hSZdKLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/kaggle_model')"
      ],
      "metadata": {
        "id": "g0AGC2O9j5ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'kaggle_model'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint],\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "6tCHEh4Ogxh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epoch 1/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 4.3083\n",
        "Epoch 1: val_loss improved from inf to 3.11947, saving model to kaggle_model\n",
        "63/63 [==============================] - 36s 423ms/step - loss: 4.3083 - val_loss: 3.1195\n",
        "Epoch 2/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.9625\n",
        "Epoch 2: val_loss improved from 3.11947 to 2.86550, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 264ms/step - loss: 2.9625 - val_loss: 2.8655\n",
        "Epoch 3/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.8231\n",
        "Epoch 3: val_loss improved from 2.86550 to 2.81203, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 259ms/step - loss: 2.8230 - val_loss: 2.8120\n",
        "Epoch 4/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7767\n",
        "Epoch 4: val_loss improved from 2.81203 to 2.77183, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 243ms/step - loss: 2.7767 - val_loss: 2.7718\n",
        "Epoch 5/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7484\n",
        "Epoch 5: val_loss improved from 2.77183 to 2.75870, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 237ms/step - loss: 2.7484 - val_loss: 2.7587\n",
        "Epoch 6/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7311\n",
        "Epoch 6: val_loss improved from 2.75870 to 2.74294, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 221ms/step - loss: 2.7311 - val_loss: 2.7429\n",
        "Epoch 7/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.7151\n",
        "Epoch 7: val_loss improved from 2.74294 to 2.73751, saving model to kaggle_model\n",
        "63/63 [==============================] - 17s 275ms/step - loss: 2.7151 - val_loss: 2.7375\n",
        "Epoch 8/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6974\n",
        "Epoch 8: val_loss improved from 2.73751 to 2.72490, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 240ms/step - loss: 2.6974 - val_loss: 2.7249\n",
        "Epoch 9/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6817\n",
        "Epoch 9: val_loss improved from 2.72490 to 2.71372, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 241ms/step - loss: 2.6817 - val_loss: 2.7137\n",
        "Epoch 10/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6527\n",
        "Epoch 10: val_loss improved from 2.71372 to 2.67398, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 253ms/step - loss: 2.6527 - val_loss: 2.6740\n",
        "Epoch 11/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6281\n",
        "Epoch 11: val_loss improved from 2.67398 to 2.65918, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 229ms/step - loss: 2.6281 - val_loss: 2.6592\n",
        "Epoch 12/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.6072\n",
        "Epoch 12: val_loss improved from 2.65918 to 2.63577, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 261ms/step - loss: 2.6072 - val_loss: 2.6358\n",
        "Epoch 13/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5828\n",
        "Epoch 13: val_loss improved from 2.63577 to 2.60439, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 241ms/step - loss: 2.5828 - val_loss: 2.6044\n",
        "Epoch 14/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5602\n",
        "Epoch 14: val_loss improved from 2.60439 to 2.59709, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 242ms/step - loss: 2.5602 - val_loss: 2.5971\n",
        "Epoch 15/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5384\n",
        "Epoch 15: val_loss improved from 2.59709 to 2.56795, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 227ms/step - loss: 2.5384 - val_loss: 2.5679\n",
        "Epoch 16/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.5222\n",
        "Epoch 16: val_loss improved from 2.56795 to 2.56513, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 235ms/step - loss: 2.5218 - val_loss: 2.5651\n",
        "Epoch 17/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.5014\n",
        "Epoch 17: val_loss improved from 2.56513 to 2.53765, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 238ms/step - loss: 2.5014 - val_loss: 2.5377\n",
        "Epoch 18/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.4828\n",
        "Epoch 18: val_loss improved from 2.53765 to 2.51946, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 232ms/step - loss: 2.4823 - val_loss: 2.5195\n",
        "Epoch 19/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.4610\n",
        "Epoch 19: val_loss improved from 2.51946 to 2.49545, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 231ms/step - loss: 2.4607 - val_loss: 2.4955\n",
        "Epoch 20/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.4367\n",
        "Epoch 20: val_loss improved from 2.49545 to 2.48011, saving model to kaggle_model\n",
        "63/63 [==============================] - 18s 287ms/step - loss: 2.4367 - val_loss: 2.4801\n",
        "Epoch 21/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.4123\n",
        "Epoch 21: val_loss improved from 2.48011 to 2.45605, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 234ms/step - loss: 2.4125 - val_loss: 2.4560\n",
        "Epoch 22/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3906\n",
        "Epoch 22: val_loss improved from 2.45605 to 2.44242, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 250ms/step - loss: 2.3906 - val_loss: 2.4424\n",
        "Epoch 23/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3700\n",
        "Epoch 23: val_loss improved from 2.44242 to 2.43009, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 245ms/step - loss: 2.3700 - val_loss: 2.4301\n",
        "Epoch 24/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3485\n",
        "Epoch 24: val_loss improved from 2.43009 to 2.39692, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 248ms/step - loss: 2.3485 - val_loss: 2.3969\n",
        "Epoch 25/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.3292\n",
        "Epoch 25: val_loss did not improve from 2.39692\n",
        "63/63 [==============================] - 4s 66ms/step - loss: 2.3288 - val_loss: 2.4199\n",
        "Epoch 26/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.3101\n",
        "Epoch 26: val_loss improved from 2.39692 to 2.39602, saving model to kaggle_model\n",
        "63/63 [==============================] - 14s 227ms/step - loss: 2.3101 - val_loss: 2.3960\n",
        "Epoch 27/30\n",
        "63/63 [==============================] - ETA: 0s - loss: 2.2905\n",
        "Epoch 27: val_loss improved from 2.39602 to 2.34717, saving model to kaggle_model\n",
        "63/63 [==============================] - 16s 258ms/step - loss: 2.2905 - val_loss: 2.3472\n",
        "Epoch 28/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.2696\n",
        "Epoch 28: val_loss improved from 2.34717 to 2.33483, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 241ms/step - loss: 2.2698 - val_loss: 2.3348\n",
        "Epoch 29/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.2510\n",
        "Epoch 29: val_loss improved from 2.33483 to 2.31494, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 243ms/step - loss: 2.2508 - val_loss: 2.3149\n",
        "Epoch 30/30\n",
        "62/63 [============================>.] - ETA: 0s - loss: 2.2310\n",
        "Epoch 30: val_loss improved from 2.31494 to 2.28819, saving model to kaggle_model\n",
        "63/63 [==============================] - 15s 242ms/step - loss: 2.2310 - val_loss: 2.2882"
      ],
      "metadata": {
        "id": "DVIP281QdN2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.title('Bi-directional LSTM+multi-self-attention in encoder Model Loss')\n",
        "\n",
        "plt.savefig(\"plot.svg\", format='svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SSQfi6kXUTiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.title('Kaggle Model Loss')\n",
        "\n",
        "plt.savefig(\"plot2.svg\", format='svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLujW1dTh6jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "model = load_model('/content/kaggle_model')\n",
        "# Pred\n",
        "preds = model.predict(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "# Convert predictions to classes\n",
        "preds_classes = np.argmax(preds, axis=-1)"
      ],
      "metadata": {
        "id": "SlX4Y-mCUZwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "model = load_model('/content/Proposed_model_5')\n",
        "# Pred\n",
        "preds = model.predict(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "# Convert predictions to classes\n",
        "preds_classes = np.argmax(preds, axis=-1)"
      ],
      "metadata": {
        "id": "eJo68S4_inAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_classes"
      ],
      "metadata": {
        "id": "vDkukw-Aavn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "zPzDcUi0bQjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds_classes:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "    preds_text.append(' '.join(temp))"
      ],
      "metadata": {
        "id": "_MHsB0z6bLiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test[:,0]))\n",
        "print(len(preds_text))"
      ],
      "metadata": {
        "id": "ANKf7UMZcayV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "metadata": {
        "id": "qkIbCxjQcLES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print 15 rows randomly\n",
        "pred_df.head(15)"
      ],
      "metadata": {
        "id": "Bz9WXaIJcnki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print 15 rows randomly\n",
        "pred_df.head(15)"
      ],
      "metadata": {
        "id": "Tz-S3gzdi9s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the path to your checkpoint directory\n",
        "checkpoint_path = '/content/kaggle_model'\n",
        "\n",
        "# Create a zip file of the checkpoints\n",
        "shutil.make_archive(checkpoint_path, 'zip', checkpoint_path)\n",
        "\n",
        "# Provide the path to the zip file\n",
        "zip_file_path = checkpoint_path + '.zip'\n",
        "\n",
        "# Move the zip file to the Colab download directory\n",
        "shutil.move(zip_file_path, '/content')\n",
        "\n",
        "# Provide the path to the zip file in the Colab download directory\n",
        "download_path = '/content/' + os.path.basename(zip_file_path)\n",
        "\n",
        "# Trigger the download of the zip file\n",
        "from google.colab import files\n",
        "files.download(download_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "LVs80I5N__HF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}